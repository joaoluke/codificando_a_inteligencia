# Introdução

**CALMA!**

Bem-vindo, esse é meu guia feito para você, isso mesmo, você que está perdido nesse mundo de IA, usa o ChatGPT, Gemini,… mas não sabe como eles funcionam por trás das cortinas, você se sente desatualizado dia após dia, pois cada dia é uma nova notícia de uma IA nova, uma ferramenta nova, pessoas anunciando o apocalipse dizendo que logo teremos a (Artificial General Intelligence, ou Inteligência Artificial Geral) e que todos seremos escravos de robôs, ou que seremos substituídos por máquinas, etc.

Calma, respira, vamos entender isso juntos. Como veio a IA, que o começo dela não foi em novembro de 2022, quando a OpenAI lançou o ChatGPT ao público, mas é um conceito muito antigo, já debatido há décadas nos meios acadêmicos.

Esse livro é uma forma que encontrei de aprender sobre IA e ao mesmo tempo passar esse conhecimento a você, então aqui é de aluno para aluno, não vou usar linguagem técnica que fará você se sentir incapacitado para acompanhar. Quero dar a você um conteúdo simples, mas rico em informações, para que você conheça a história da IA, a base da IA, sendo a matemática, até chegarmos a assuntos complexos.

Então fique tranquilo, se você se dedicar a ler esse livro, não vai precisar comprar curso caro da internet sobre IA, ou ficar em fórum em inglês, ou buscar outras fontes nesse mar de informações e acabar se perdendo, confie em mim, quero guiar você até você ter um pleno conhecimento sobre inteligência artificial e não achar que ela é uma caixa mágica onde extraterrestres jogaram aqui para nós e estamos usando desde então. Pois essa é a minha jornada de aprendizado também. E de quebra vai ganhar umas pitadas de opiniões pessoais minhas sobre o assunto (isso é bom ou ruim? Descubra!).

---

**O que é Inteligência Artificial?**

Bom, podemos começar falando de como foi a origem da inteligência artificial na história ou filosófica, temos o mito de Talos da Grécia antiga que era um gigante de bronze autômato ou do Golem da tradição judaica, mas aí vamos perder muito tempo, começaremos um debate filosófico que pode não ter fim.

Nós, seres humanos, sempre imaginamos coisas superiores a nós, coisas mais rápidas, mais fortes, maiores, como (dragões, gigantes, etc.), e na questão de inteligência não é diferente, veja o exemplo de Albert Einstein, foi um grande cientista, mas nós o colocamos quase como um deus, um sinônimo de inteligência, tanto que quando colocamos "Einstein" em qualquer assunto, parece que ganha mais credibilidade, mas teve outros cientistas tão ou até mais brilhantes que ele, como Schrodinger, Gödel, Dennis Ritchie, entre outros.

Então, a inteligência artificial é uma ideia que já está conosco há muito tempo, mas seremos práticos, né? Vamos ao que interessa (não que essa história seja desinteressante, muito pelo contrário, recomendo você a estudar, pois é um estudo muito longo e complexo) foi no século 19 que um cara chamado Charles Babbage provou que a IA pode ter uma forma mecânica, sem ele, ela ainda seria um conceito filosófico, e no século 20 com um matemático chamado John Von Neumann ajudou a criar a arquitetura computacional que usamos até hoje, onde a IA pode ser criada e claro o nosso querido pai da computação Alan Turing que nos trouxe a primeira grande indagação quando publicou "Computing Machinery and Intelligence" fazendo a pergunta: "Máquinas podem pensar?", isso foi tão grandioso que nessa publicação ele "abriu o jogo" e propôs o que ele chamou de "O jogo da imitação".

E esse jogo de Turing é bem simples: um cara fica numa sala fazendo perguntas, e em outra sala onde ele não pode ver, tem pessoas e uma máquina, o objetivo é o interrogador descobrir quem respondeu sua pergunta, se foi um humano ou uma máquina, se a máquina enganar ele, ela passou no teste. Tanto que eu acredito que, quando forem olhar esse nosso período na história, vão chamar "o período que a máquina passou no teste de Turing", pois o seu professor é esperto o suficiente para saber que o texto que você entregou a ele foi o ChatGPT que fez? Pensa que marco grandioso chegamos. Mas fica tranquilo, não quer dizer que as máquinas vão tomar controle do mundo, me acompanha no decorrer desse livro e você vai ver.

Para a pergunta que fiz no título dessa seção não "passar batido" ou ficar implícita no texto, vamos dizer que a inteligência artificial é uma forma do computador resolver problemas, tomar decisão e fazer o uso de dados e informação, isso pode parecer uma imitação da nossa inteligência, mas é bem mais que isso, se alguém que entende mesmo de inteligência artificial ler o que acabei de dizer, pode querer me bater. Mas prometo que no decorrer do livro vamos atualizando e melhorando essa definição.

Tá bom, eu sei, você quer algo mais confiável que a palavra de um cara que você acabou de conhecer, eu entendo e admiro você por isso. Como uma definição, vamos trazer os nossos caros Russell & Norvig para nos falar o que é a inteligência artificial: “Artificial Intelligence is the study of agents that receive percepts from the environment and take actions that maximize their chances of achieving their goals.” que quer dizer: "IA é o estudo de agentes que percebem o ambiente e agem para maximizar objetivos." Você entendeu algo? Eu também não, mas vamos entender juntos.

---

**Qual a história da IA?**

Já falei um pouco da história, falei de Turing, de Von Neumann, de Babbage, e apenas joguei Stuart Russell e Peter Norvig no meio do nosso papo, sem nem apresentá-los direito, perdão! Ambos escreveram um livro que se chama "Artificial Intelligence: A Modern Approach" que é um dos livros mais influentes na IA, e que eu recomendo que você leia, bom, vamos nos aprofundar um pouco, vamos voltar um pouco no tempo e falar sobre o início da IA no meio acadêmico e no campo da pesquisa.

#### A Conferência de Dartmouth (1956)

Para a gente não voltar muito no tempo, vamos começar com nosso já conhecido Alan Turing, ele foi um cara que despertou a ideia sobre como um computador pode imitar a inteligência humana, o que antes era uma ideia filosófica de se o computador pode pensar ou não, ele transforma em um problema cientifico e testável, e foi em 1956 na conferência de Dartmouth realizada na Universidade de Dartmouth nos Estados Unidos que o termo "inteligência artificial" foi usado pela primeira vez, e nessa ocasião tínhamos nomes como Claude Shannon (pai da teoria da informação), John McCarthy (criador da linguagem de programação Lisp), Marvin Minsky (criador do laboratório de IA do MIT), entre outros. E a ideia era bem ambiciosa para a época, eles achavam que poderiam criar a IA nos padrões que temos hoje em dia com ChatGPT, Gemini, etc., em apenas 2 meses. 

Mas esse nome que eles deram, "inteligência artificial", não agradou a todos, e até hoje é um termo muito debatido, porque isso dá a nós a ideia de que a IA é como se fosse nossa inteligência humana, só que perfeita, sem erros, sem limitações, mas aí que está um grande defeito de nós programadores: somos péssimos para dar nomes às coisas. Para esse início de conversa, vamos ficar com: a IA é uma forma que demos ao computador de resolver problemas que antes exigiam inteligência humana. Mas não é com a nossa inteligência que ele está resolvendo esses problemas (mais tarde vamos ver isso mais a fundo). Tá bom, eu sei o que você está pensando, "mas João, o ChatGPT me responde como uma pessoa, ele demonstra sentimentos, ele é inteligente". Calma, calma, calma, vamos chegar lá.

#### A Era Simbólica e o "Se/Então"

Então, depois dessa conferência, eles viram que "o buraco é mais embaixo", que era uma ideia muito complexa para ser resolvida naquela época, principalmente pelo poder computacional que tinham, mas mesmo assim o mundo gostou da ideia. Eu acho que o termo "inteligência artificial" pode ter sido proposital mesmo, para chamar a atenção, dar marketing e ganhar desejos das pessoas por tal tecnologia. E isso deu certo, organizações governamentais amaram essa ideia, imagina para eles ter tanques pilotando sozinhos, então foi onde tivemos a era simbólica da IA nos anos 60, onde tudo o que tínhamos eram muitos if/else nos códigos, literalmente. Para você que pode não ser programador, o if/else é uma forma de você executar um bloco de código dada uma sentença:

```python
if (condição): # Se a condição for verdadeira, executa esse bloco de código
    pass
else: # Se a condição for falsa, executa esse bloco de código
    pass
```

Então, os softwares de inteligência artificial eram um monte de ifs e elses, o que era uma loucura, por exemplo, para falar sobre um determinado assunto ele precisava ter um código gigante "se isso, se aquilo, se aquilo outro..." e assim por diante, era uma coisa muito limitada, se você perguntasse algo que não estava no banco de dados, ele não saberia responder, se fizesse uma pergunta de uma forma diferente do que ele estava programado para entender, ele não saberia responder. 

Mas mesmo assim tivemos softwares que se destacaram nessa época, como o ELIZA, que foi criado por Joseph Weizenbaum em 1966. Ele era um programa que simulava uma conversa entre um psicólogo e um paciente, e ele era capaz de responder perguntas de forma coerente, mas ele não entendia o que estava falando, ele apenas seguia regras pré-definidas. Tipo, se você falasse "eu estou triste", ele responderia "por que você está triste?", se você falasse "eu estou feliz", ele responderia "por que você está feliz?", e assim por diante. Ele pegava uma palavra-chave da sua frase e respondia de acordo com a regra que ele tinha. Se ele visse a palavra "mãe" no texto, ele logo iria entender problemas familiares e responder de acordo com a regra que ele tinha.

Era algo cansativo de fazer, imagina pensar nas milhares de possibilidades de uma conversa e ter que codificar a resposta de cada uma? Mas mesmo com esse software tão simples, teve um relato da própria assistente do Dr. Weizenbaum, que se apegou ao software, pediu para que ele não desligasse o computador, porque ela estava conversando com ele e não queria parar. Como uma opinião minha, nós amamos a ideia do computador, poder fazer tarefas nele, executar jogos, softwares, ele se tornou nossa ferramenta favorita, e com a ideia dele rodar uma "inteligência" parecida com a nossa, ficamos ainda mais eufóricos.

#### O inverno da IA

Por mais que tenha colocado o título dessa seção no singular, a história da inteligência artificial teve vários invernos, ela é cheia de altos e baixos, mas vamos falar das partes baixas primeiro (não nesse sentido), brincadeiras à parte, depois da conferência de Dartmouth, com todo aquele otimismo e ambição de que em um verão iriam criar a inteligência artificial, acabou criando muita expectativa com isso, bom, aí você já deve imaginar o que vem em seguida, né?

Esse termo "inverno da IA" pode parecer algo criado por historiadores recentemente para dar nome a esse período de baixa da IA, mas na verdade foi criado pelo próprio Roger Schank e Marvin Minsky, em 1984, na reunião anual da American Association for Artificial Intelligence (AAAI). Para você entender: eles estavam numa balada, estava todo mundo ficando doidão e dando PT, e aí eles falam "cuidado, pois amanhã a ressaca vai ser grande", e é exatamente isso que aconteceu. Naquela época, a euforia era tão grande, mas ambos já tinham vivenciado os períodos de crise da IA na década de 1970 e então sabiam o que podia vir pela frente. O engraçado é que, 3 anos depois dessa fala deles, o mercado que valia bilhões de dólares começou a definhar. E um dos termos usados por eles foi bem pesado, eles compararam esse inverno da inteligência artificial ao inverno nuclear, que iria começar com pessimismo da comunidade, iria chegar na mídia que, por sua vez, iria fazer com que os cortes de investimento acontecessem, acabando com a pesquisa séria.

O principal inverno da IA aconteceu entre 1987 e 2000, e foi um período de grande desilusão para a comunidade de IA. Os pesquisadores haviam prometido muito, mas não conseguiram entregar quase nada do que prometeram, entretanto não vou aprofundar muito nesse período, mas vou dizer que entregaram coisas importantes como: planejamento simbólico, os sistemas especialistas, heurísticas, etc. Os computadores da época não eram poderosos o suficiente para lidar com a complexidade dos problemas que estavam tentando resolver, e os algoritmos eram muito limitados. Como resultado, os investimentos em IA diminuíram drasticamente, e a área entrou em declínio. Mas antes vamos falar do primeiro inverno que foi entre 1974 até 1980, e também foi um período de bastante desilusão, o que acarretou em cortes de investimentos e o fim de muitos projetos.

Isso começou com as promessas das traduções automáticas. Como os EUA estavam no meio da Guerra Fria, eles precisavam de uma forma de traduzir os documentos russos rapidamente, então eles investiram pesado em IA para criar um software que pudesse traduzir textos automaticamente. Com isso, em 1954, houve uma demonstração do Georgetown-IBM experiment, que foi capaz de traduzir mais de 60 frases do russo para o inglês. Foi uma grande euforia, manchetes como: "A máquina bilíngue", "Cérebro robótico traduz russo para inglês britânico" e "Criação poliglota". Mas aí entra o grande BO dessa invenção, eram apenas 50 frases escolhidas a dedo para que a máquina não errasse, o que limitava seu vocabulário a 250 palavras, e ao nível de comparação, para termos uma boa compreensão de um texto, precisamos de em torno de 8000 famílias de palavras, o que faz essa máquina ser uma piada de mau gosto, pois o grande problema da máquina era que ela não entendia o contexto, ela apenas traduzia palavra por palavra, e como o inglês e o russo têm ordens de palavras diferentes, a máquina acabava errando feio. Por exemplo, a frase "The spirit is willing but the flesh is weak" (O espírito está disposto, mas a carne é fraca) foi traduzida como "The vodka is good but the meat is rotten" (A vodca está boa, mas a carne está podre). E então, em 1964, foi realizado o conselho de ALPAC (Automatic Language Processing Advisory Committee), que foi um conselho criado pelo governo americano para avaliar o progresso da tradução automática. E o relatório que eles publicaram foi desastroso, eles disseram que a tradução automática era uma piada e que não tinha futuro. Resultando em? Isso mesmo, corte de verbas. Depois de mais de 20 milhões de dólares investidos, o governo americano cortou o financiamento de pesquisa em tradução automática, e a área entrou em declínio.

Sinto lhe informar, meu caro, mas não foi apenas essa área que começou a entrar em colapso, é como o bom e velho efeito dominó, quando uma peça cai, todas as outras caem em seguida. E próxima a cair foi os Perceptrons que era a rede neural da época criada por Frank Rosenblatt em 1957, que era uma rede neural artificial que era capaz de aprender a reconhecer padrões em dados, grande parte da empolgação da área era por causa de seu criador que tinha uma personalidade forte. Então, em 1969, o mesmo Marvin Minsky e Seymour Papert publicaram um livro chamado Perceptrons, que foi um livro que basicamente destruiu a reputação dos perceptrons. Eles mostraram que os perceptrons eram limitados e que não eram capazes de resolver problemas complexos. Com isso, foi ficando escasso o investimento para a área de Redes Neurais, mas voltou a crescer em meados da década de 1980, quando o trabalho de John Hopfield, David Rumelhart e outros reavivou o interesse em larga escala. Pena que nosso amigo Frank Rosenblatt não viu isso, pois faleceu em um acidente de barco pouco depois da publicação de Perceptrons.

E bom, você acha que essa onda assolou apenas os Estados Unidos? Que nada, essa onda de pessimismo atravessou o Atlântico e foi bater na porta do Reino Unido com o chamado Relatório Lighthill em 1973, que foi um relatório que basicamente destruiu a reputação da IA no Reino Unido. E apontaram um problema técnico bem cabal à explosão combinatória, que basicamente diz que os problemas se tornam exponencialmente mais difíceis de resolver à medida que aumentamos a quantidade de variáveis. Ou seja, os problemas da vida real, né? De que adianta uma máquina que consegue resolver problemas simples, mas não consegue resolver problemas complexos? Com isso, o campo de pesquisa em IA ficou praticamente uma década estagnado.

E, voltando aos EUA, a DARPA (Defense Advanced Research Projects Agency), que era a principal financiadora de pesquisas em IA, começou a ficar sem paciência com tantos projetos que não apresentavam resultados promissores, e começou a perder a fé mesmo nessa tecnologia. Muitos pesquisadores, como Hans Moravec, culparam alguns dos colegas pesquisadores, pois sempre ficavam prometendo coisas que jamais iriam conseguir cumprir, e sempre que faziam um novo pedido de verbas, eles inventavam mais promessas vazias, ou seja, a culpa não era apenas da euforia dos pesquisadores.

Depois do congelamento dos anos 70, a IA voltou a ganhar força nos anos 80 com o chamado boom dos sistemas especialistas, que eram sistemas de IA capazes de resolver problemas em domínios específicos, como diagnóstico médico e análise financeira. Essa nova onda de "piração de cabeção coletiva" fez empresas investirem mais de um bilhão de dólares, e para rodar esses sistemas surgiram os chamados Lisp Machines, que eram computadores especializados em rodar programas em Lisp, a linguagem de programação mais popular na época para desenvolvimento de IA. Computadores caros, software caro, mas ambos limitadíssimos, o que fez com que essa bolha estourasse em 1987, com a queda da bolsa de valores e o colapso do mercado de Lisp Machines, e fez um mercado de meio bilhão de dólares desaparecer em um único ano.

Em suma, o que foi um divisor de águas para essa que chamo de a tempestade perfeita foi o fato de que os computadores da época, os Workstations da Sun Microsystems, ficaram tão potentes e baratos que não compensava comprar os computadores caros que faziam apenas uma coisa, e então começou a queda com o hardware, mas você deve estar se perguntando: "E o software? Não cumpria o seu dever?" Aí vem o segundo problema: os sistemas especialistas eram caros de manter e atualizar, e quebravam com facilidade quando se deparavam com uma situação inesperada, ou seja, eles eram muito limitados, e não conseguiam aprender sozinhos. 

Achou que eu ia deixar os japoneses de fora dessa história? Claro que não, em 1981 o governo japonês lançou o chamado Projeto Computador de Quinta Geração, que era um projeto ambicioso que visava desenvolver computadores que fossem capazes de resolver problemas complexos, raciocinar como humanos e conversar entre si, e em 1991 o projeto acabou não com rugidos, mas com gemidos.

Então, depois desses vários fatores, o termo que temos como moda hoje em dia, "inteligência artificial", ficou em baixa, a palavra podia até ser tóxica para algumas pessoas/organizações. Nos anos 90, inícios dos anos 2000, ninguém queria nem saber de IA, os pesquisadores da área, para não se misturar com esse termo, tiveram que rebatizar o campo para alguns nomes até que criativos: "inteligência computacional", "aprendizado de máquina", "sistemas baseados em inteligência", qualquer coisa para não serem associados ao termo.

Bom, mas olha a mágica da história entrando em ação, enquanto a IA ficava em baixa, a tecnologia que ela precisava para se tornar possível estava evoluindo aos poucos, de forma silenciosa, o que se tornou a grande contranarrativa desse período, o que levou Rodney Brooks a afirmar na mesma época que "existe esse mito estúpido de que a IA falhou, mas a IA está ao seu redor a cada segundo do dia." 

Ok, depois de tudo isso que falamos até agora, quero sentar frente a frente contigo, olho no olho, precisamos esclarecer algumas coisas para você não sair dessa parte confuso. Quero que entenda que a IA não falhou, o que falhou fomos nós (é claro), o grande problema dessa epoca não foi querer fazer maquinas inteligentes (aqui quero que voce grave uma coisa: "maquina inteligente" não é uma maquina que tem a mesma inteligencia que voce, é apenas uma maquina que resolve problemas que voce resolveria, mas isso não quer dizer que ela pensa igual voce, esqueça isso, ela jamais vai pensar como nós, lembra do exemplo da bola de futebol, ela pode se mover de um ponto A até o ponto B, igual um carro, mas não quer dizer que ela seja um carro, sacou?), o grande problema era passar a nossa inteligencia para a maquina, isso é algo muito dificil de acontecer, por que por mais que possa ter um programa que simule as decisões de um medico, como "se o paciente está com febre e dor de cabeça, ele pode estar com gripe", isso muitas das vezes era verdade, mas às vezes não e o medico sabe disso, é o famoso "feeling", aquele conhecimento tacito que não conseguimos explica. Seria o mesmo que pedir ao Neymar para nos ajudar a criar um conjunto de regras que qualquer um que aplicasse, jogaria da mesma forma que o nosso camisa 10.

Por mais que possa ter parecido, o problema nunca foi o algoritmo e sim o ambiente em que ele foi executado. Naquela época, os computadores eram fracos, não tinham muita memória RAM (aquela memória que permite você abrir 20 abas do Google Chrome de uma só vez), não tinham GPU (o processamento gráfico, aquelas placas de vídeo caras que seu filho fala que é para ajudar ele nos estudos) e, claro, ainda não havia a quantidade de dados que temos hoje em dia para treinar nossos modelos. Então, Deep Learning não é uma ideia nova, é uma ideia que esperou o hardware certo.

E você lembra que falamos que os pesquisadores rebatizaram os seus estudos porque existia uma "caça às bruxas da IA" naquele tempo? Então, um dos termos que surgiu foi "aprendizado de máquina", que acho que você já deve ter ouvido falar, não é? Aqui começam muitas ideias que nos ajudaram a chegar onde estamos hoje, mas isso é uma história para outro dia.

Agora que estamos conversados, podemos seguir?

### Referências Bibliográficas

RUSSELL, Stuart J.; NORVIG, Peter. **Inteligência Artificial: uma abordagem moderna**. 4. ed. Rio de Janeiro: Elsevier, 2021.

*João Lucas, 2024.*
